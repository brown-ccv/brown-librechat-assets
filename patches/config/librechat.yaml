 # For more information, see the Configuration Guide:
    # https://www.librechat.ai/docs/configuration/librechat_yaml

    # Configuration version (required)
    version: 1.2.1

    # Cache settings: Set to true to enable caching
    cache: true

    # Custom interface configuration
    interface:
      customWelcome: "Welcome to LibreChat! Enjoy your experience."
      
      # Privacy policy settings
      privacyPolicy:
        externalUrl: "https://librechat.ai/privacy-policy"
        openNewTab: true

      # Terms of service
      termsOfService:
        externalUrl: "https://docs.ccv.brown.edu/ai-tools/terms-of-use"
        openNewTab: true
        modalAcceptance: true
        modalTitle: "Terms of Service for Brown-LibreChat"
        modalContent: |
         For a comprehensive overview of our policies, usage guidelines, and user responsibilities, we encourage you to review our  <a href="https://docs.ccv.brown.edu/ai-tools/terms-of-use" target="_blank" rel="noopener noreferrer">Terms of Service</a>. This document outlines the conditions under which our platform and services are provided.
      endpointsMenu: true
      modelSelect: true
      parameters: true
      sidePanel: true
      # presets: true
      prompts: true
      bookmarks: true
      multiConvo: true
      agents: true
    
    registration:
      socialLogins: ['github', 'google', 'discord', 'openid', 'facebook', 'apple']

    endpoints:
      azureOpenAI:
        # Endpoint-level configuration
        #titleModel: "Llama-3.3-70B-Instruct"
        fileSizeLimit: 5000
        groups:
        ### keep this entry here while we continue testing.
        # - group: "gpt-4o"
        #   apiKey: "${AZURE_OPENAI_API_KEY}"
        #   baseURL: "https://ccv-ai.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview"
        #   instanceName: "ccv-ai"
        #   version: "${OPENAI_API_VERSION}"
        #   # Model-level configuration
        #   models:
        #     gpt-4o:
        #       deploymentName: "gpt-4o"
        #       version: "${OPENAI_API_VERSION}"
        - group: "gpt-4o"
          apiKey: "${LLAMA_KEY}"
          serverless: true
          baseURL: "https://yxu15-m8exsnfh-eastus2.openai.azure.com/openai/deployments/gpt-4o"
          version: "2024-12-01-preview"
          models:
             # Must match the deployment name of the model
             gpt-4o:
              deploymentName: "gpt-4o"
        - group: "gpt-4o-mini"
          apiKey: "${LLAMA_KEY}"
          serverless: true
          baseURL: "https://yxu15-m8exsnfh-eastus2.openai.azure.com/openai/deployments/gpt-4o-mini"
          version: "2024-12-01-preview"
          models:
             # Must match the deployment name of the model
             gpt-4o-mini:
              deploymentName: "gpt-4o-mini"
        - group: "o1-mini"
          apiKey: "${LLAMA_KEY}"
          serverless: true
          baseURL: "https://yxu15-m8exsnfh-eastus2.openai.azure.com/openai/deployments/o1-mini"
          version: "2024-12-01-preview"
          models:
             # Must match the deployment name of the model
             o1-mini:
              deploymentName: "o1-mini"
        - group: "Llama-3.3"
          apiKey: "${LLAMA_KEY}"
          baseURL: "https://yxu15-m8exsnfh-eastus2.services.ai.azure.com/models"
          version: "2024-05-01-preview" # Optional: specify API version
          serverless: true
          models:
             # Must match the deployment name of the model
             Llama-3.3-70B-Instruct: true
        - group: "DeepSeek-V3"
          apiKey: "${LLAMA_KEY}"
          baseURL: "https://yxu15-m8exsnfh-eastus2.services.ai.azure.com/models"
          serverless: true
          models:
             # Must match the deployment name of the model
             DeepSeek-V3-0324: true

    fileConfig:
      serverFileSizeLimit: 5000